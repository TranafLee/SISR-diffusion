23-07-01 11:24:29.408 - INFO:   name: sr_ffhq
  phase: train
  gpu_ids: [0]
  path:[
    log: experiments/sr_ffhq_230701_112429/logs
    tb_logger: experiments/sr_ffhq_230701_112429/tb_logger
    results: experiments/sr_ffhq_230701_112429/results
    checkpoint: experiments/sr_ffhq_230701_112429/checkpoint
    resume_state: None
    experiments_root: experiments/sr_ffhq_230701_112429
  ]
  datasets:[
    train:[
      name: FFHQ
      mode: HR
      dataroot: dataset/ffhq_16_128
      datatype: lmdb
      l_resolution: 16
      r_resolution: 128
      batch_size: 4
      num_workers: 8
      use_shuffle: True
      data_len: -1
    ]
    val:[
      name: CelebaHQ
      mode: LRHR
      dataroot: dataset/celebahq_16_128
      datatype: lmdb
      l_resolution: 16
      r_resolution: 128
      data_len: 3
    ]
  ]
  model:[
    which_model_G: sr3
    finetune_norm: False
    unet:[
      in_channel: 6
      out_channel: 3
      inner_channel: 64
      channel_multiplier: [1, 2, 4, 8, 8]
      attn_res: [16]
      res_blocks: 2
      dropout: 0.2
    ]
    beta_schedule:[
      train:[
        schedule: linear
        n_timestep: 2000
        linear_start: 1e-06
        linear_end: 0.01
      ]
      val:[
        schedule: linear
        n_timestep: 2000
        linear_start: 1e-06
        linear_end: 0.01
      ]
    ]
    diffusion:[
      image_size: 128
      channels: 3
      conditional: True
    ]
  ]
  train:[
    n_iter: 1000000
    val_freq: 10000.0
    save_checkpoint_freq: 10000.0
    print_freq: 200
    optimizer:[
      type: adam
      lr: 0.0001
    ]
    ema_scheduler:[
      step_start_ema: 5000
      update_ema_every: 1
      ema_decay: 0.9999
    ]
  ]
  wandb:[
    project: sr_ffhq
  ]
  distributed: False
  log_wandb_ckpt: False
  log_eval: False
  enable_wandb: False

